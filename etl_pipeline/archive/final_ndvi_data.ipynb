{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHJyImLDtP3I"
      },
      "source": [
        "Testing on 2022 OHIO data on google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ipqZ35rB2lM",
        "outputId": "4792d7ce-62ad-4336-b2c5-17476dff8a7a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUbH92OsDH3v",
        "outputId": "c7b8172f-53d5-49b1-9fc0-f561abfd4abc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Base NDVI folder\n",
        "base_folder = \"/content/drive/MyDrive/MlOps_Project/NDVI\"\n",
        "\n",
        "# List of years to process\n",
        "years = [\"2017\",\"2018\",\"2019\",\"2020\",\"2021\", \"2022\"]\n",
        "\n",
        "# Placeholder for NDVI results\n",
        "ndvi_records = []\n",
        "\n",
        "for year in years:\n",
        "    year_folder = os.path.join(base_folder, year)\n",
        "\n",
        "    # Loop over states inside year\n",
        "    for state_folder in os.listdir(year_folder):\n",
        "        state_path = os.path.join(year_folder, state_folder)\n",
        "\n",
        "        if not os.path.isdir(state_path):\n",
        "            continue  # Skip non-folder files\n",
        "\n",
        "        # Loop over H5 files inside state folder\n",
        "        for filename in os.listdir(state_path):\n",
        "            if filename.endswith(\".h5\"):\n",
        "                file_path = os.path.join(state_path, filename)\n",
        "                print(f\"Processing {file_path}\")\n",
        "\n",
        "                try:\n",
        "                    with h5py.File(file_path, \"r\") as f:\n",
        "                        for fips in f.keys():\n",
        "                            for date in f[fips].keys():\n",
        "                                group = f[fips][date]\n",
        "\n",
        "                                if \"data\" not in group:\n",
        "                                    print(f\"⚠️ No 'data' in {filename} -> {fips} / {date}\")\n",
        "                                    continue\n",
        "\n",
        "                                try:\n",
        "                                    data = group[\"data\"][:]  # (time, height, width, bands)\n",
        "\n",
        "                                    for i, tile in enumerate(data):\n",
        "                                        # Assume [Red, NIR] band order\n",
        "                                        red = tile[:, :, 0].astype(np.float32)\n",
        "                                        nir = tile[:, :, 1].astype(np.float32)\n",
        "\n",
        "                                        ndvi = (nir - red) / (nir + red + 1e-5)\n",
        "                                        ndvi = np.clip(ndvi, -1, 1)\n",
        "\n",
        "                                        mean_ndvi = np.nanmean(ndvi)\n",
        "\n",
        "                                        if mean_ndvi > 0:  # Filter directly during processing\n",
        "                                            ndvi_records.append({\n",
        "                                                \"year\": year,\n",
        "                                                \"fips\": fips,\n",
        "                                                \"date\": date,\n",
        "                                                \"tile_index\": i,\n",
        "                                                \"mean_ndvi\": mean_ndvi\n",
        "                                            })\n",
        "\n",
        "                                except Exception as e:\n",
        "                                    print(f\"Error processing {filename} -> {fips}/{date}: {e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Cannot open file {filename}: {e}\")\n",
        "\n",
        "# Now create final DataFrame\n",
        "output_df = pd.DataFrame(ndvi_records)\n",
        "\n",
        "# Group by year, fips, date and take the mean NDVI\n",
        "grouped_df = output_df.groupby([\"year\", \"fips\", \"date\"]).agg({\n",
        "    \"mean_ndvi\": \"mean\"\n",
        "}).reset_index()\n",
        "\n",
        "# Save final big CSV\n",
        "csv_path = os.path.join(\"/content/drive/MyDrive/MlOps_Project/\", \"ndvi_summary_all_years.csv\")\n",
        "grouped_df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Final NDVI summary saved to: {csv_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.4 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c5f29ab0bd70a3fdfe3350be4806661ff87a7ec1a414855bb5824b269ce85de1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
