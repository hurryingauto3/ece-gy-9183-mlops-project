{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the county shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading tl_2022_us_county.zip...\n",
      "âœ… Downloaded.\n",
      "ðŸ“¦ Unzipping to ./dataset/county_shapefiles/tl_2022_us_county...\n",
      "âœ… Unzipped.\n",
      "âœ… Loaded shapefile for 2022. Columns: ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'GEOID', 'NAME', 'NAMELSAD', 'LSAD', 'CLASSFP', 'MTFCC', 'CSAFP', 'CBSAFP', 'METDIVFP', 'FUNCSTAT', 'ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON', 'geometry']\n",
      "  STATEFP COUNTYFP  COUNTYNS  GEOID       NAME          NAMELSAD LSAD CLASSFP  \\\n",
      "0      31      039  00835841  31039     Cuming     Cuming County   06      H1   \n",
      "1      53      069  01513275  53069  Wahkiakum  Wahkiakum County   06      H1   \n",
      "2      35      011  00933054  35011    De Baca    De Baca County   06      H1   \n",
      "3      31      109  00835876  31109  Lancaster  Lancaster County   06      H1   \n",
      "4      31      129  00835886  31129   Nuckolls   Nuckolls County   06      H1   \n",
      "\n",
      "   MTFCC CSAFP CBSAFP METDIVFP FUNCSTAT       ALAND    AWATER     INTPTLAT  \\\n",
      "0  G4020  None   None     None        A  1477644346  10691216  +41.9158651   \n",
      "1  G4020  None   None     None        A   680980770  61564427  +46.2946377   \n",
      "2  G4020  None   None     None        A  6016818946  29090018  +34.3592729   \n",
      "3  G4020  None   None     None        A  2169272978  22847034  +40.7835474   \n",
      "4  G4020  None   None     None        A  1489645185   1718484  +40.1764918   \n",
      "\n",
      "       INTPTLON                                           geometry  \n",
      "0  -096.7885168  POLYGON ((-96.55516 41.91587, -96.55515 41.914...  \n",
      "1  -123.4244583  POLYGON ((-123.72755 46.2645, -123.72756 46.26...  \n",
      "2  -104.3686961  POLYGON ((-104.89337 34.08894, -104.89337 34.0...  \n",
      "3  -096.6886584  POLYGON ((-96.68493 40.5233, -96.69219 40.5231...  \n",
      "4  -098.0468422  POLYGON ((-98.2737 40.1184, -98.27374 40.1224,...  \n"
     ]
    }
   ],
   "source": [
    "def download_tiger_counties(year: int, output_dir: str = \"./dataset/county_shapefiles\"):\n",
    "    \"\"\"\n",
    "    Downloads TIGER/Line U.S. county shapefile for a specific year and unzips it.\n",
    "    Returns the path to the extracted shapefile.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://www2.census.gov/geo/tiger/TIGER{year}/COUNTY/\"\n",
    "    filename = f\"tl_{year}_us_county.zip\"\n",
    "    download_url = base_url + filename\n",
    "\n",
    "    # Create directory if not exists\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    zip_path = os.path.join(output_dir, filename)\n",
    "    extract_path = os.path.join(output_dir, f\"tl_{year}_us_county\")\n",
    "\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"â¬‡ï¸ Downloading {filename}...\")\n",
    "        response = requests.get(download_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(\"âœ… Downloaded.\")\n",
    "        else:\n",
    "            raise Exception(f\"âŒ Failed to download: {download_url} (Status code: {response.status_code})\")\n",
    "\n",
    "    # Unzip if not already extracted\n",
    "    if not os.path.exists(extract_path):\n",
    "        print(f\"ðŸ“¦ Unzipping to {extract_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"âœ… Unzipped.\")\n",
    "    else:\n",
    "        print(f\"ðŸ“ Already unzipped: {extract_path}\")\n",
    "\n",
    "    return extract_path\n",
    "\n",
    "def load_county_shapefile(year: int, output_dir: str = \"./dataset/county_shapefiles\") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Loads the unzipped shapefile for the specified year into a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    shapefile_dir = download_tiger_counties(year, output_dir)\n",
    "    shp_file = [f for f in os.listdir(shapefile_dir) if f.endswith(\".shp\")][0]\n",
    "    shp_path = os.path.join(shapefile_dir, shp_file)\n",
    "\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    print(f\"âœ… Loaded shapefile for {year}. Columns: {list(gdf.columns)}\")\n",
    "    return gdf\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    year = 2022  # You can loop over [2017, 2018, ..., 2022]\n",
    "    counties_gdf = load_county_shapefile(year)\n",
    "    print(counties_gdf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the cdl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2022_30m_cdls.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022_30m_cdls.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.93G/1.93G [04:09<00:00, 8.28MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] Download complete: ./dataset/cdl_data/2022_30m_cdls.zip\n",
      "Unzipping 2022_30m_cdls.zip...\n",
      "[âœ“] Unzipped to: ./dataset/cdl_data/2022\n"
     ]
    }
   ],
   "source": [
    "def download_national_cdl(years, out_dir='./dataset/cdl_data'):\n",
    "    base_url = \"https://www.nass.usda.gov/Research_and_Science/Cropland/Release/datasets/\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for year in years:\n",
    "        filename = f\"{year}_30m_cdls.zip\"\n",
    "        url = base_url + filename\n",
    "        zip_path = os.path.join(out_dir, filename)\n",
    "        extract_path = os.path.join(out_dir, str(year))\n",
    "\n",
    "        if os.path.exists(extract_path):\n",
    "            print(f\"[âœ“] Already extracted: {extract_path}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"[!] Failed to download: {filename}\")\n",
    "                continue\n",
    "\n",
    "            total = int(response.headers.get('content-length', 0))\n",
    "            with open(zip_path, 'wb') as file, tqdm(\n",
    "                desc=filename, total=total, unit='iB', unit_scale=True, unit_divisor=1024\n",
    "            ) as bar:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "\n",
    "            print(f\"[âœ“] Download complete: {zip_path}\")\n",
    "        else:\n",
    "            print(f\"[âœ“] Already downloaded: {zip_path}\")\n",
    "\n",
    "        # Unzip the file\n",
    "        print(f\"Unzipping {filename}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(f\"[âœ“] Unzipped to: {extract_path}\")\n",
    "\n",
    "# Download 2017â€“2022 CDL national files\n",
    "years_to_download = list(range(2022, 2023))\n",
    "download_national_cdl(years_to_download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [ 1/1 ], Downloading USDA Data, Year: 2022, Crop: Corn\n",
      "Progress: [ 1/1 ], Downloading USDA Data, Year: 2022, Crop: Cotton\n",
      "Progress: [ 1/1 ], Downloading USDA Data, Year: 2022, Crop: Soybean\n",
      "Progress: [ 1/1 ], Downloading USDA Data, Year: 2022, Crop: WinterWheat\n"
     ]
    }
   ],
   "source": [
    "from cropnet.data_downloader import DataDownloader\n",
    "\n",
    "# Initialize the downloader with your target directory\n",
    "downloader = DataDownloader(target_dir=\"./dataset\")\n",
    "\n",
    "years = [\"2022\"]\n",
    "crops = ['Corn', 'Cotton', 'Soybean', 'WinterWheat']\n",
    "\n",
    "\n",
    "\n",
    "for crop in crops:\n",
    "    downloader.download_USDA(crop, fips_codes=None, years=years)\n",
    "    \n",
    "# sentiel-2 ndvi data and hrrr was downloaded from an online drive linked to a colab file on cropnet's official hugging face "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5f29ab0bd70a3fdfe3350be4806661ff87a7ec1a414855bb5824b269ce85de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
