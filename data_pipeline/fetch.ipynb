{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the county shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiger_counties(year: int, output_dir: str = \"./dataset/county_shapefiles\"):\n",
    "    \"\"\"\n",
    "    Downloads TIGER/Line U.S. county shapefile for a specific year and unzips it.\n",
    "    Returns the path to the extracted shapefile.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://www2.census.gov/geo/tiger/TIGER{year}/COUNTY/\"\n",
    "    filename = f\"tl_{year}_us_county.zip\"\n",
    "    download_url = base_url + filename\n",
    "\n",
    "    # Create directory if not exists\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    zip_path = os.path.join(output_dir, filename)\n",
    "    extract_path = os.path.join(output_dir, f\"tl_{year}_us_county\")\n",
    "\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        response = requests.get(download_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(\"Downloaded.\")\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download: {download_url} (Status code: {response.status_code})\")\n",
    "\n",
    "    # Unzip if not already extracted\n",
    "    if not os.path.exists(extract_path):\n",
    "        print(f\"Unzipping to {extract_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"Unzipped.\")\n",
    "    else:\n",
    "        print(f\"Already unzipped: {extract_path}\")\n",
    "\n",
    "    return extract_path\n",
    "\n",
    "def load_county_shapefile(year: int, output_dir: str = \"./dataset/county_shapefiles\") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Loads the unzipped shapefile for the specified year into a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    shapefile_dir = download_tiger_counties(year, output_dir)\n",
    "    shp_file = [f for f in os.listdir(shapefile_dir) if f.endswith(\".shp\")][0]\n",
    "    shp_path = os.path.join(shapefile_dir, shp_file)\n",
    "\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    print(f\"Loaded shapefile for {year}. Columns: {list(gdf.columns)}\")\n",
    "    return gdf\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    year = 2022  # You can loop over [2017, 2018, ..., 2022]\n",
    "    counties_gdf = load_county_shapefile(year)\n",
    "    print(counties_gdf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the cdl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_national_cdl(years, out_dir='./dataset/cdl_data'):\n",
    "    base_url = \"https://www.nass.usda.gov/Research_and_Science/Cropland/Release/datasets/\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for year in years:\n",
    "        filename = f\"{year}_30m_cdls.zip\"\n",
    "        url = base_url + filename\n",
    "        zip_path = os.path.join(out_dir, filename)\n",
    "        extract_path = os.path.join(out_dir, str(year))\n",
    "\n",
    "        if os.path.exists(extract_path):\n",
    "            print(f\"[✓] Already extracted: {extract_path}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"[!] Failed to download: {filename}\")\n",
    "                continue\n",
    "\n",
    "            total = int(response.headers.get('content-length', 0))\n",
    "            with open(zip_path, 'wb') as file, tqdm(\n",
    "                desc=filename, total=total, unit='iB', unit_scale=True, unit_divisor=1024\n",
    "            ) as bar:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "\n",
    "            print(f\"[✓] Download complete: {zip_path}\")\n",
    "        else:\n",
    "            print(f\"[✓] Already downloaded: {zip_path}\")\n",
    "\n",
    "        # Unzip the file\n",
    "        print(f\"Unzipping {filename}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(f\"[✓] Unzipped to: {extract_path}\")\n",
    "\n",
    "# Download 2017–2022 CDL national files\n",
    "years_to_download = list(range(2022, 2023))\n",
    "download_national_cdl(years_to_download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cropnet.data_downloader import DataDownloader\n",
    "\n",
    "# Initialize the downloader with your target directory\n",
    "downloader = DataDownloader(target_dir=\"./dataset\")\n",
    "\n",
    "years = [\"2022\"]\n",
    "crops = ['Corn', 'Cotton', 'Soybean', 'WinterWheat']\n",
    "\n",
    "\n",
    "\n",
    "for crop in crops:\n",
    "    downloader.download_USDA(crop, fips_codes=None, years=years)\n",
    "    \n",
    "# sentiel-2 ndvi data and hrrr was downloaded from an online drive linked to a colab file on cropnet's official hugging face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cropnet.data import DataDownloader\n",
    "\n",
    "# Set parameters\n",
    "state = \"IA\"             # Iowa\n",
    "county_fips = 19109      # Kossuth County\n",
    "year = 2020              # Choose year\n",
    "crop = \"corn\"            # Crop type (needed even if you only want Sentinel NDVI)\n",
    "\n",
    "# Initialize downloader\n",
    "downloader = DataDownloader(\n",
    "    output_dir=\"./cropnet_data\", \n",
    "    states=[state],\n",
    "    crops=[crop],\n",
    "    years=[year]\n",
    ")\n",
    "\n",
    "# Download data\n",
    "downloader.pull()\n",
    "\n",
    "print(\"Download complete. Check './cropnet_data'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
